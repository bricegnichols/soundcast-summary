{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- produce csv output summary of daysim results for use in tableau and other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import h5py\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h5_to_df(h5file, table_list, name=False):\n",
    "    \"\"\"\n",
    "    Load h5-formatted data based on a table list. Assumes heirarchy of a set of tables.\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    \n",
    "    for table in table_list:\n",
    "        df = pd.DataFrame()\n",
    "        for field in h5file[table].keys():\n",
    "            df[field] = h5file[table][field][:]\n",
    "            \n",
    "        output_dict[table] = df\n",
    "    \n",
    "    if name:\n",
    "        output_dict['name'] = name\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_row(df, row_name, description, value):\n",
    "    df.ix[row_name,'description'] = description\n",
    "    df.ix[row_name,'value'] = value\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(r'variable_labels.csv')\n",
    "districts = pd.read_csv(r'data/district_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of runs to add to the analysis, to come from the script argument (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_lables(h5data):\n",
    "    '''\n",
    "    Replace daysim formatted values with human readable lablels.\n",
    "    '''\n",
    "    for table in labels['table'].unique():\n",
    "        df = labels[labels['table'] == table]\n",
    "        for field in df['field'].unique():\n",
    "            newdf = df[df['field'] == field]\n",
    "            local_series = pd.Series(newdf['text'].values, index=newdf['value'])\n",
    "            h5data[table][field] = h5data[table][field].map(local_series)\n",
    "    \n",
    "    return h5data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_dataset(h5file, scenario_name):\n",
    "    \n",
    "    # Process all daysim results\n",
    "    \n",
    "    # Load h5 data as dataframes\n",
    "    dataset = h5_to_df(h5file, table_list=['Household','Trip','Tour','Person','HouseholdDay','PersonDay'], name=scenario_name)\n",
    "\n",
    "    dataset = apply_lables(dataset)\n",
    "    \n",
    "    # Calculate aggregate measures csv\n",
    "    agg_df = agg_measures(dataset)\n",
    "    write_csv(agg_df,fname='agg_measures.csv')\n",
    "\n",
    "    tours_df = tours(dataset)\n",
    "    write_csv(tours_df,fname='tours.csv')\n",
    "    \n",
    "    taz_df = taz_tours(dataset)\n",
    "    write_csv(taz_df,fname='taz_tours.csv')\n",
    "    \n",
    "    trips_df = trips(dataset)\n",
    "    write_csv(trips_df, fname='trips.csv')\n",
    "    \n",
    "    person_day_df = person_day(dataset)\n",
    "    write_csv(person_day_df, fname='person_day.csv')\n",
    "    \n",
    "    person_df = person(dataset)\n",
    "    write_csv(person_df, 'person.csv')\n",
    "    \n",
    "    tod_df = time_of_day(dataset)\n",
    "    write_csv(tod_df, fname='time_of_day.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv(df,fname):\n",
    "    '''\n",
    "    Write dataframe to file; append existing file\n",
    "    '''\n",
    "#     df.to_csv(os.path.join(output_dir,fname),mode='a')\n",
    "    if not os.path.isfile(os.path.join(output_dir,fname)):\n",
    "        df.to_csv(os.path.join(output_dir,fname))\n",
    "    else: # append without writing the header\n",
    "        df.to_csv(os.path.join(output_dir,fname), mode ='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def agg_measures(dataset):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Total Persons\n",
    "    df = add_row(df, row_name='total_persons', description='Total Persons', value=dataset['Person']['psexpfac'].sum())\n",
    "\n",
    "    # Total Households\n",
    "    df = add_row(df, row_name='total_hhs', description='Total Households', value=dataset['Household']['hhexpfac'].sum())\n",
    "\n",
    "    # Average Household Size\n",
    "    avg_hh_size = (dataset['Household']['hhsize']*dataset['Household']['hhexpfac']).sum()/dataset['Household']['hhexpfac'].sum()\n",
    "    df = add_row(df, row_name='avg_hh_size', description='Average Household Size', value=avg_hh_size)\n",
    "\n",
    "    # Average Trips per Person\n",
    "    trips_per_person = dataset['Trip']['trexpfac'].sum()/dataset['Person']['psexpfac'].sum()\n",
    "    df = add_row(df, row_name='trips_per_person', description='Average Trips per Person', value=trips_per_person)\n",
    "\n",
    "    # Average Trip Length\n",
    "    trip_len = (dataset['Trip']['travdist']*dataset['Trip']['trexpfac']).sum()/dataset['Trip']['trexpfac'].sum()\n",
    "    df = add_row(df, row_name='trip_len', description='Average Trips Length', value=trip_len)\n",
    "\n",
    "    # VMT per capita\n",
    "    driver_trips = dataset['Trip'][dataset['Trip']['dorp'] == 'Driver']\n",
    "    vmt_per_cap = (driver_trips['travdist']*driver_trips['trexpfac']).sum()/dataset['Person']['psexpfac'].sum()\n",
    "    df = add_row(df, row_name='vmt_per_cap', description='VMT per Person', value=vmt_per_cap)\n",
    "\n",
    "    # Average distance to work\n",
    "    to_work_tours = dataset['Tour'][dataset['Tour']['pdpurp'] == 'Work']\n",
    "    dist_to_work = (to_work_tours['tautodist']*to_work_tours['toexpfac']).sum()/to_work_tours['toexpfac'].sum()\n",
    "    df = add_row(df, row_name='dist_to_work', description='Avg Distance to Work', value=dist_to_work)\n",
    "\n",
    "    # Average distance to school\n",
    "    to_school_tours = dataset['Tour'][dataset['Tour']['pdpurp'] == 'School']\n",
    "    dist_to_school = (to_school_tours['tautodist']*to_school_tours['toexpfac']).sum()/to_school_tours['toexpfac'].sum()\n",
    "    df = add_row(df, row_name='dist_to_school', description='Avg Distance to School', value=dist_to_school)\n",
    "    \n",
    "    # add datasource field\n",
    "    df['source'] = dataset['name']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def person_day(dataset):\n",
    "    \n",
    "    # total number of persons by purpose and person type\n",
    "    person = dataset['Person']\n",
    "    personday = dataset['PersonDay']\n",
    "\n",
    "    # join with person records to get person type\n",
    "    df = pd.merge(person,personday,on=['hhno','pno'])\n",
    "\n",
    "    # calculate weighted tours for each group\n",
    "    purp_fields = ['wk','sc','es','pb','sh','ml','so']\n",
    "    purp_dict = {'wk':'work', 'sc':'school', 'es':'escort','pb':'personal business','sh':'shop','ml':'meal','so':'social'}\n",
    "\n",
    "    for field in purp_fields:\n",
    "        df['wt_'+field] = df[field+'tours']*df['pdexpfac']\n",
    "\n",
    "    df = pd.DataFrame(df.groupby('pptyp').sum()[['psexpfac','pdexpfac']+['wt_'+field for field in purp_fields]])\n",
    "    for field in purp_fields:\n",
    "        df[purp_dict[field]] = df['wt_'+field]/df['psexpfac']\n",
    "        df.drop('wt_'+field,axis=1,inplace=True)\n",
    "\n",
    "    df.drop(['psexpfac','pdexpfac'],axis=1,inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(df.stack())\n",
    "    df.columns = ['values']\n",
    "    df['pptyp'] = df.index.get_level_values(0)\n",
    "    df['measure'] = df.index.get_level_values(1)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    df['source'] = dataset['name']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tours(dataset):\n",
    "    \n",
    "    tour = dataset['Tour']\n",
    "    person = dataset['Person']\n",
    "        \n",
    "    # total tours\n",
    "    # join with person file and district names based on destination\n",
    "    tour_person = pd.merge(tour,person,on=['hhno','pno'])\n",
    "    tour_person = pd.merge(tour_person,districts[['taz','district_name']],left_on='tdtaz',right_on='taz',how='left')\n",
    "    \n",
    "    \n",
    "    tour_person['tlvorig_hr'] = tour_person['tlvorig'].apply(lambda row: int(math.floor(row/60)))\n",
    "    \n",
    "    # Tours by person type, purpose, mode, destination district, and time of day\n",
    "    agg_fields = ['pptyp','pdpurp','tmodetp','tlvorig_hr','district_name']\n",
    "    tours_df = pd.DataFrame(tour_person.groupby(agg_fields)['toexpfac'].sum())\n",
    "    \n",
    "    # average trip distance and time\n",
    "    tours_df = tours_df.join(pd.DataFrame(tour_person.groupby(agg_fields)['tautodist'].mean()))\n",
    "    tours_df = tours_df.join(pd.DataFrame(tour_person.groupby(agg_fields)['tautotime'].mean()))\n",
    "    # average trip \n",
    "    \n",
    "    tours_df = tours_df.join(pd.DataFrame(person.groupby('pptyp').sum()['psexpfac']))\n",
    "    \n",
    "    # Add the district lat and lon values\n",
    "    tours_df['pptyp'] = tours_df.index.get_level_values(0)\n",
    "    tours_df['pdpurp'] = tours_df.index.get_level_values(1)\n",
    "    tours_df['tmodetp'] = tours_df.index.get_level_values(2)\n",
    "    tours_df['tlvorig_hr'] = tours_df.index.get_level_values(3)\n",
    "    tours_df['district_name'] = tours_df.index.get_level_values(4)\n",
    "    tours_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    district_df = districts.groupby('district_name').min()[['lat_district','lon_district']]\n",
    "    district_df['district_name'] = district_df.index\n",
    "\n",
    "    tours_df = pd.merge(tours_df,district_df)\n",
    "    \n",
    "    # add datasource field\n",
    "    tours_df['source'] = dataset['name']\n",
    "    \n",
    "    return tours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trips(dataset):\n",
    "    \n",
    "    trip = dataset['Trip']\n",
    "    person = dataset['Person']\n",
    "        \n",
    "    # total trips\n",
    "    # join with person file and district names based on destination\n",
    "    trip_person = pd.merge(trip,person,on=['hhno','pno'])\n",
    "    \n",
    "    trip_person['deptm_hr'] = trip_person['deptm'].apply(lambda row: int(math.floor(row/60)))\n",
    "    \n",
    "    # Tours by person type, purpose, mode, and destination district\n",
    "    agg_fields = ['pptyp','dpurp','mode','deptm_hr']\n",
    "    trips_df = pd.DataFrame(trip_person.groupby(agg_fields)['trexpfac'].sum())\n",
    "    \n",
    "    # average trip distance and time\n",
    "    trips_df = trips_df.join(pd.DataFrame(trip_person.groupby(agg_fields)['travdist'].mean()))\n",
    "    trips_df = trips_df.join(pd.DataFrame(trip_person.groupby(agg_fields)['travtime'].mean()))\n",
    "    # average trip \n",
    "    \n",
    "    trip_person = trip_person.join(pd.DataFrame(person.groupby('pptyp').sum()['psexpfac']),\n",
    "                                   lsuffix='_x', rsuffix='_y')\n",
    "    \n",
    "    # add datasource field\n",
    "    trips_df['source'] = dataset['name']\n",
    "    \n",
    "    return trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def taz_tours(dataset):\n",
    "    \n",
    "    tour = dataset['Tour']\n",
    "    \n",
    "#   tour_dest = pd.merge(tour,districts[['taz','district_name','lat','lon']],left_on='tdtaz',right_on='taz',how='left')\n",
    "    tour_dest = pd.DataFrame(tour.groupby('tdtaz').sum()['toexpfac'])\n",
    "    tour_dest['taz'] = tour_dest.index\n",
    "    tour_dest.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "#     tour_origin = pd.merge(tour,districts[['taz','district_name','lat','lon']],left_on='totaz',right_on='taz',how='left')\n",
    "    tour_origin = pd.DataFrame(tour.groupby('totaz').sum()['toexpfac'])\n",
    "    tour_origin['taz'] = tour_origin.index\n",
    "    tour_origin.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df = pd.merge(tour_dest,tour_origin,on='taz', suffixes=['_dest','_origin'])\n",
    "    df = pd.merge(df,districts, on='taz',how='left' )\n",
    "    \n",
    "    df['source'] = dataset['name']\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def network_results(model_dir, dataset_name):\n",
    "    '''\n",
    "    Process network-level soundcast results and export to csv\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_excel(os.path.join(model_dir,r'outputs/network_summary_detailed.xlsx'), sheetname='Network Summary')\n",
    "    # drop first row if it's empty (older version of the summary)\n",
    "    if pd.isnull(df['arterial_vmt'].iloc[0]):\n",
    "        print 'test'\n",
    "        try: \n",
    "            df.drop('tod',axis=0,inplace=True)\n",
    "            df['tod'] = df.index\n",
    "            \n",
    "        except:\n",
    "            print 'format error in network_summary'\n",
    "    else:\n",
    "        df.index = df['tod']\n",
    "\n",
    "    df = pd.DataFrame(df.stack())\n",
    "    \n",
    "    df['tod'] = df.index.get_level_values(0)\n",
    "    df['fieldname'] = df.index.get_level_values(1)\n",
    "    df.rename(columns={0:'model_value'},inplace=True)\n",
    "\n",
    "    # Drop the rows with TP_4k column headers\n",
    "    df.drop(df[df['fieldname'] == 'TP_4k'].index, inplace=True)\n",
    "    df.drop(df[df['fieldname'] == 'tod'].index, inplace=True)\n",
    "    \n",
    "    # Split the fields by vmt, vht, delay\n",
    "    df['facility_type'] = df.fieldname.apply(lambda row: row.split('_')[0])\n",
    "    df['metric'] = df.fieldname.apply(lambda row: row.split('_')[-1])\n",
    "\n",
    "    # add dataset name\n",
    "    df['source'] = dataset_name\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_of_day(dataset):\n",
    "    \"\"\"\n",
    "    tours and trips by time of day hour\n",
    "    \"\"\"\n",
    "    trip = dataset['Trip']\n",
    "    tour = dataset['Tour']\n",
    "    \n",
    "    # Trip start hour\n",
    "    trip['deptm_hr'] = trip['deptm'].apply(lambda row: int(math.floor(row/60)))\n",
    "    trip['arrtm_hr'] = trip['arrtm'].apply(lambda row: int(math.floor(row/60)))\n",
    "    \n",
    "    # tour start hour\n",
    "    tour['tlvorg_hr'] = tour['tlvorig'].apply(lambda row: int(math.floor(row/60)))\n",
    "    tour['tardest_hr'] = tour['tardest'].apply(lambda row: int(math.floor(row/60)))\n",
    "    tour['tlvdest_hr'] = tour['tlvdest'].apply(lambda row: int(math.floor(row/60)))\n",
    "    tour['tarorig_hr'] = tour['tarorig'].apply(lambda row: int(math.floor(row/60)))\n",
    "    \n",
    "   \n",
    "    trip_dep = pd.DataFrame(trip.groupby('deptm_hr').sum()['trexpfac'])\n",
    "    trip_dep['tod'] = trip_dep.index\n",
    "    trip_dep.reset_index(inplace=True)\n",
    "    trip_dep.rename(columns={'trexpfac':'trip_deptm'},inplace=True)\n",
    "        \n",
    "    trip_arr = pd.DataFrame(trip.groupby('arrtm_hr').sum()['trexpfac'])\n",
    "    trip_arr['tod'] = trip_arr.index\n",
    "    trip_arr.reset_index(inplace=True)\n",
    "    trip_arr.rename(columns={'trexpfac':'trip_arrtm'},inplace=True)\n",
    "    \n",
    "    results_df = pd.merge(trip_dep, trip_arr, on='tod')\n",
    "    \n",
    "    results_df['source'] = dataset['name']\n",
    "    \n",
    "    return results_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def person(dataset):\n",
    "    \n",
    "    hh = dataset['Household']\n",
    "    person = dataset['Person']\n",
    "\n",
    "    person_hh = pd.merge(person, hh, on='hhno')\n",
    "\n",
    "    # district_df = pd.DataFrame(district.groupby('district_name').min())\n",
    "    person_hh = pd.merge(person_hh,districts[['taz','district_name']],left_on='hhtaz',right_on='taz', how='left')\n",
    "\n",
    "    df = pd.DataFrame(person_hh.groupby(['pptyp','district_name']).sum()['psexpfac'])\n",
    "    \n",
    "    df['pptyp'] = df.index.get_level_values(0)\n",
    "    df['district_name'] = df.index.get_level_values(1)\n",
    "    \n",
    "    districts_df = districts.groupby('district_name').min()[['lat_district','lon_district']]\n",
    "    df.index = df['district_name']\n",
    "    \n",
    "    df = df.join(districts_df,how='left')\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    df['source'] = dataset['name']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing soundcast_2014.h5\n",
      "processing survey_2006.h5\n",
      "processing survey_2014.h5\n",
      "processing tFutures_2010.h5\n"
     ]
    }
   ],
   "source": [
    "# model_runs = [r'R:\\SoundCast\\releases\\TransportationFutures2010',\n",
    "#               r'R:\\SoundCast\\releases\\soundcast_release_c1']\n",
    "\n",
    "# model_runs = [r'Q:\\stefan\\soundcast_runtime_test\\soundcast',\n",
    "#              r'R:\\SoundCast\\releases\\TransportationFutures2010']\n",
    "\n",
    "# Assume standard path for survey, which can be overridden as arg\n",
    "# survey_dir = r'R:\\SoundCast\\Inputs\\2014\\etc\\survey.h5'\n",
    "\n",
    "output_dir = r'J:\\projects\\soundcast\\soundcast_dashboard\\model_output'\n",
    "overwrite = True\n",
    "\n",
    "if overwrite:\n",
    "    for fname in ['agg_measures','trips','taz_tours','tours','time_of_day','person_day']:\n",
    "        if os.path.isfile(os.path.join(output_dir,fname+'.csv')):\n",
    "            os.remove(os.path.join(output_dir,fname+'.csv'))\n",
    "\n",
    "survey_added = False\n",
    "\n",
    "# Save daysim-formatted output to a folder - rename h5 file to scenario name\n",
    "h5_dir = r'C:\\daysim_comparison'\n",
    "\n",
    "\n",
    "# Get all files with h5 extension in h5_dir\n",
    "\n",
    "for fname in os.listdir(h5_dir):\n",
    "    if fname.endswith('.h5'):\n",
    "\n",
    "        # Process daysim results\n",
    "\n",
    "    #     daysim_h5 = h5py.File(os.path.join(model_dir,r'outputs/daysim_outputs.h5'))\n",
    "        daysim_h5 = h5py.File(os.path.join(h5_dir,fname))\n",
    "        # name of scenario is last level of directory\n",
    "    #     scenario_name = os.path.basename(model_dir)\n",
    "\n",
    "        print 'processing ' + fname\n",
    "\n",
    "        # Perform calculations and export to csv\n",
    "        process_dataset(h5file=daysim_h5, scenario_name=fname.split('.')[0])\n",
    "\n",
    "        del daysim_h5 # drop from memory to save space for next comparison\n",
    "\n",
    "#         if not survey_added:\n",
    "#             print 'processing: survey'\n",
    "\n",
    "#             survey_h5 = h5py.File(survey_dir)\n",
    "#             process_dataset(h5file=survey_h5, scenario_name='survey')\n",
    "\n",
    "#             survey_added = True\n",
    "        \n",
    "#     # Process network results\n",
    "#     network_df = network_results(model_dir, dataset_name=scenario_name)\n",
    "#     write_csv(network_df, fname='network_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# survey = h5py.File(r'Q:\\stefan\\soundcast_remove_skims\\soundcast\\outputs\\daysim_outputs.h5')\n",
    "survey = h5py.File(r'R:\\SoundCast\\Inputs\\2014\\etc\\survey.h5')\n",
    "dataset = h5_to_df(survey, table_list=['Household','Trip','Tour','Person','HouseholdDay','PersonDay'], name='test')\n",
    "dataset = apply_lables(dataset)\n",
    "\n",
    "tour = dataset['Tour']\n",
    "person = dataset['Person']\n",
    "personday = dataset['PersonDay']\n",
    "# tour_person = pd.merge(tour,person[['hhno','pno','pptyp']],on=['hhno','pno'])\n",
    "\n",
    "# person.to_csv(os.path.join(output_dir,'person_survey.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
